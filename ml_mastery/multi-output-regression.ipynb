{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Tutorial Overview\n",
    "This tutorial is divided into five parts; they are:\n",
    "\n",
    "1. Problem of Multioutput Regression\n",
    "    - Check Scikit-Learn Version\n",
    "    - Multioutput Regression Test Problem\n",
    "2. Inherently Multioutput Regression Algorithms\n",
    "    - Linear Regression for Multioutput Regression\n",
    "    - k-Nearest Neighbors for Multioutput Regression\n",
    "    - Evaluate Multioutput Regression With Cross-Validation\n",
    "3. Wrapper Multioutput Regression Algorithms\n",
    "4. Direct Multioutput Regression\n",
    "5. Chained Multioutput Regression -->\n",
    "\n",
    "Source: [machinelearningmastery multi-output-regression][1]\n",
    "\n",
    "[1]: https://machinelearningmastery.com/multi-output-regression-models-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem of Multioutput Regression\n",
    "Regression refers to a predictive modeling problem that involves predicting a numerical value.\n",
    "\n",
    "For example, predicting a size, weight, amount, number of sales, and number of clicks are regression problems. Typically, a single numeric value is predicted given input variables.\n",
    "\n",
    "Some regression problems require the prediction of two or more numeric values. For example, predicting an x and y coordinate. These problems are referred to as multiple-output regression, or multioutput regression.\n",
    "\n",
    "- **Regression:** Predict a single numeric output given an input.\n",
    "- **Multioutput Regression:** Predict two or more numeric outputs given an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multioutput regression, typically the outputs are dependent upon the input and upon each other. This means that often the outputs are not independent of each other and may require a model that predicts both outputs together or each output contingent upon the other outputs.\n",
    "\n",
    "Multi-step time series forecasting may be considered a type of multiple-output regression where a sequence of future values are predicted and each predicted value is dependent upon the prior values in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the make_regression() function to create a test dataset for multiple-output regression. We will generate 1,000 examples with 10 input features, five of which will be redundant and five that will be informative. The problem will require the prediction of two numeric values.\n",
    "\n",
    "- **Problem Input**: 10 numeric variables.\n",
    "- **Problem Output**: 2 numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X,y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some regression machine learning algorithms support multiple outputs directly. This includes most of the popular machine learning algorithms implemented in the scikit-learn library, such as:\n",
    "\n",
    "- LinearRegression (and related)\n",
    "- KNeighborsRegressor\n",
    "- DecisionTreeRegressor\n",
    "- RandomForestRegressor (and related)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression for Multioutput Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50.06781717 64.564973  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X, y)\n",
    "X_test = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
    "y_lr_pred = model_lr.predict([X_test])\n",
    "print(y_lr_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors for Multioutput Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.73511093  52.78406297]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model_knr = KNeighborsRegressor()\n",
    "model_knr.fit(X, y)\n",
    "y_knr_pred = model_knr.predict([X_test])\n",
    "print(y_knr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree for Multioutput Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49.93137149 64.08484989]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_dtr = DecisionTreeRegressor()\n",
    "model_dtr.fit(X,y)\n",
    "y_dtr_pred = model_dtr.predict([X_test])\n",
    "print(y_dtr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Multioutput Regression With Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 52.285 (3.407)\n"
     ]
    }
   ],
   "source": [
    "from numpy import absolute, mean, std\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "# create datasets\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Multioutput Regression Algorithms\n",
    "Not all regression algorithms support multioutput regression.\n",
    "\n",
    "One example is the support vector machine, although for regression, it is referred to as support vector regression, or SVR.\n",
    "\n",
    "This algorithm does not support multiple outputs for a regression problem and will raise an error. We can demonstrate this with an example, listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (1000, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\github_projects\\study-time-series-analysis\\ml_mastery\\multi-output-regression.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/github_projects/study-time-series-analysis/ml_mastery/multi-output-regression.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m LinearSVR()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/github_projects/study-time-series-analysis/ml_mastery/multi-output-regression.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/github_projects/study-time-series-analysis/ml_mastery/multi-output-regression.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# (THIS WILL CAUSE AN ERROR!)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/github_projects/study-time-series-analysis/ml_mastery/multi-output-regression.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "File \u001b[1;32mg:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:556\u001b[0m, in \u001b[0;36mLinearSVR.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    532\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    533\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \n\u001b[0;32m    535\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[39m        An instance of the estimator.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    557\u001b[0m         X,\n\u001b[0;32m    558\u001b[0m         y,\n\u001b[0;32m    559\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    560\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    561\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    562\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    564\u001b[0m     penalty \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# SVR only accepts l2 penalty\u001b[39;00m\n\u001b[0;32m    566\u001b[0m     _dual \u001b[39m=\u001b[39m _validate_dual_parameter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss, penalty, \u001b[39m\"\u001b[39m\u001b[39movr\u001b[39m\u001b[39m\"\u001b[39m, X)\n",
      "File \u001b[1;32mg:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mg:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1163\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[0;32m   1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1167\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mg:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1184\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1183\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m-> 1184\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1185\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, estimator_name\u001b[39m=\u001b[39mestimator_name)\n\u001b[0;32m   1186\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[1;32mg:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1245\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1234\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1235\u001b[0m             (\n\u001b[0;32m   1236\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1241\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   1242\u001b[0m         )\n\u001b[0;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_order(xp\u001b[39m.\u001b[39mreshape(y, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,)), order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, xp\u001b[39m=\u001b[39mxp)\n\u001b[1;32m-> 1245\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1246\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[0;32m   1247\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1000, 2) instead."
     ]
    }
   ],
   "source": [
    "# failure of support vector regression for multioutput regression (causes an error)\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.svm import LinearSVR\n",
    "# create datasets\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n",
    "# define model\n",
    "model = LinearSVR()\n",
    "# fit model\n",
    "# (THIS WILL CAUSE AN ERROR!)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports (`ValueError: bad input shape (1000, 2)`) an error message indicating that the model does not support multioutput regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(all text are copied from [machinelearningmastery multi-output-regression][1])\n",
    "\n",
    "[1]: https://machinelearningmastery.com/multi-output-regression-models-with-python/\n",
    "\n",
    "A workaround for using regression models designed for predicting one value for multioutput regression is to divide the multioutput regression problem into multiple sub-problems.\n",
    "\n",
    "The most obvious way to do this is to split a multioutput regression problem into multiple single-output regression problems.\n",
    "\n",
    "For example, if a multioutput regression problem required the prediction of three values y1, y2 and y3 given an input X, then this could be partitioned into three single-output regression problems:\n",
    "\n",
    "- **Problem 1**: Given X, predict y1.\n",
    "- **Problem 2**: Given X, predict y2.\n",
    "- **Problem 3**: Given X, predict y3.\n",
    "\n",
    "There are two main approaches to implementing this technique.\n",
    "\n",
    "### The first approach is good for neighbours \n",
    "The first approach involves developing a separate regression model for each output value to be predicted. We can think of this as a direct approach, as each target value is modeled directly.\n",
    "\n",
    "\n",
    "### The second approach is good for \n",
    "The second approach is an extension of the first method except the models are organized into a chain. The prediction from the first model is taken as part of the input to the second model, and the process of output-to-input dependency repeats along the chain of models.\n",
    "\n",
    "- **Direct Multioutput**: Develop an independent model for each numerical value to be predicted.\n",
    "- **Chained Multioutput**: Develop a sequence of dependent models to match the number of numerical values to be predicted.\n",
    "Let’s take a closer look at each of these techniques in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Multioutput Regression\n",
    "\n",
    "The direct approach to multioutput regression involves dividing the regression problem into a separate problem for each target variable to be predicted.\n",
    "\n",
    "This assumes that the outputs are independent of each other, which might not be a correct assumption. Nevertheless, this approach can provide surprisingly effective predictions on a range of problems and may be worth trying, at least as a performance baseline.\n",
    "\n",
    "For example, the outputs for your problem may, in fact, be mostly independent, if not completely independent, and this strategy can help you find out.\n",
    "\n",
    "This approach is supported by the [MultiOutputRegressor][2] class that takes a regression model as an argument. It will then create one instance of the provided model for each output in the problem.\n",
    "\n",
    "[2]: https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\n",
    "\n",
    "```\n",
    "# define base model\n",
    "model = LinearSVR()\n",
    "# define the direct multioutput wrapper model\n",
    "wrapper = MultiOutputRegressor(model)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.419 (0.024)\n"
     ]
    }
   ],
   "source": [
    "# example of evaluating direct multioutput regression with an SVM model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "# define base model\n",
    "model = LinearSVR()\n",
    "# define the direct multioutput wrapper model\n",
    "wrapper = MultiOutputRegressor(model)\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(wrapper, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the direct multioutput regression wrapper as a final model and make predictions on new data.\n",
    "\n",
    "First, the model is fit on all available data, then the predict() function can be called to make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "g:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[50.04979758 64.50953349]]\n"
     ]
    }
   ],
   "source": [
    "# example of making a prediction with the direct multioutput regression model\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "# define base model\n",
    "model = LinearSVR()\n",
    "# define the direct multioutput wrapper model\n",
    "wrapper = MultiOutputRegressor(model)\n",
    "# fit the model on the whole dataset\n",
    "wrapper.fit(X, y)\n",
    "# make a single prediction\n",
    "X_test = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
    "y_wr_pred = wrapper.predict([X_test])\n",
    "# summarize the prediction\n",
    "print('Predicted: %s' % y_wr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained Multioutput Regression\n",
    "Another approach to using single-output regression models for multioutput regression is to create a linear sequence of models.\n",
    "\n",
    "The first model in the sequence uses the input and predicts one output; the second model uses the input and the output from the first model to make a prediction; the third model uses the input and output from the first two models to make a prediction, and so on.\n",
    "\n",
    "For example, if a multioutput regression problem required the prediction of three values y1, y2 and y3 given an input X, then this could be partitioned into three dependent single-output regression problems as follows:\n",
    "\n",
    "- **Problem 1**: Given X, predict y1.\n",
    "- **Problem 2**: Given X and yhat1, predict y2.\n",
    "- **Problem 3**: Given X, yhat1, and yhat2, predict y3.\n",
    "\n",
    "This can be achieved using the [RegressorChain][3] class in the scikit-learn library.\n",
    "\n",
    "[3]: https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.RegressorChain.html\n",
    "\n",
    "The order of the models may be based on the order of the outputs in the dataset (the default) or specified via the “order” argument. For example, order=[0,1] would first predict the oth output, then the 1st output, whereas an order=[1,0] would first predict the last output variable and then the first output variable in our test problem.\n",
    "\n",
    "The example below demonstrates how we can first create a single-output regression model then use the RegressorChain class to wrap the regression model and add support for multioutput regression.\n",
    "\n",
    "```\n",
    "# define base model\n",
    "model = LinearSVR()\n",
    "# define the chained multioutput wrapper model\n",
    "wrapper = RegressorChain(model, order=[0,1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.611 (0.268)\n"
     ]
    }
   ],
   "source": [
    "# example of evaluating chained multioutput regression with an SVM model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.svm import LinearSVR\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "# define base model\n",
    "model = LinearSVR()\n",
    "# define the chained multioutput wrapper model\n",
    "wrapper = RegressorChain(model)\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(wrapper, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[50.017815   65.04742335]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "g:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "g:\\github_projects\\study-time-series-analysis\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# example of making a prediction with the chained multioutput regression model\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.svm import LinearSVR\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "# define base model\n",
    "model = LinearSVR()\n",
    "# define the chained multioutput wrapper model\n",
    "wrapper = RegressorChain(model)\n",
    "# fit the model on the whole dataset\n",
    "wrapper.fit(X, y)\n",
    "# make a single prediction\n",
    "X_test = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
    "y_wr2_pred = wrapper.predict([X_test])\n",
    "# summarize the prediction\n",
    "print('Predicted: %s' % y_wr2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
